{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "SEED=42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:27:50.187664Z",
     "iopub.status.busy": "2025-09-09T05:27:50.186851Z",
     "iopub.status.idle": "2025-09-09T05:27:50.250945Z",
     "shell.execute_reply": "2025-09-09T05:27:50.250068Z",
     "shell.execute_reply.started": "2025-09-09T05:27:50.187639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:27:59.908871Z",
     "iopub.status.busy": "2025-09-09T05:27:59.908093Z",
     "iopub.status.idle": "2025-09-09T05:29:21.240072Z",
     "shell.execute_reply": "2025-09-09T05:29:21.239259Z",
     "shell.execute_reply.started": "2025-09-09T05:27:59.908844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/input/news-summarization/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T05:05:32.437623Z",
     "iopub.status.busy": "2025-09-08T05:05:32.436810Z",
     "iopub.status.idle": "2025-09-08T05:05:32.455594Z",
     "shell.execute_reply": "2025-09-08T05:05:32.454921Z",
     "shell.execute_reply.started": "2025-09-08T05:05:32.437589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York police are concerned drones could bec...</td>\n",
       "      <td>Police have investigated criminals who have ri...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By . Ryan Lipman . Perhaps Australian porn sta...</td>\n",
       "      <td>Porn star Angela White secretly filmed sex act...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was, Sergio Garcia conceded, much like be...</td>\n",
       "      <td>American draws inspiration from fellow country...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An Ebola outbreak that began in Guinea four mo...</td>\n",
       "      <td>World Health Organisation: 635 infections and ...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By . Associated Press and Daily Mail Reporter ...</td>\n",
       "      <td>A sinkhole opened up at 5:15am this morning in...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  New York police are concerned drones could bec...   \n",
       "1  By . Ryan Lipman . Perhaps Australian porn sta...   \n",
       "2  This was, Sergio Garcia conceded, much like be...   \n",
       "3  An Ebola outbreak that began in Guinea four mo...   \n",
       "4  By . Associated Press and Daily Mail Reporter ...   \n",
       "\n",
       "                                             Summary         Dataset  \n",
       "0  Police have investigated criminals who have ri...  CNN/Daily Mail  \n",
       "1  Porn star Angela White secretly filmed sex act...  CNN/Daily Mail  \n",
       "2  American draws inspiration from fellow country...  CNN/Daily Mail  \n",
       "3  World Health Organisation: 635 infections and ...  CNN/Daily Mail  \n",
       "4  A sinkhole opened up at 5:15am this morning in...  CNN/Daily Mail  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T14:31:39.898377Z",
     "iopub.status.busy": "2025-09-08T14:31:39.898125Z",
     "iopub.status.idle": "2025-09-08T14:31:40.053380Z",
     "shell.execute_reply": "2025-09-08T14:31:40.052653Z",
     "shell.execute_reply.started": "2025-09-08T14:31:39.898352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 0\",\"ID\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:38:38.726667Z",
     "iopub.status.busy": "2025-09-07T05:38:38.726398Z",
     "iopub.status.idle": "2025-09-07T05:38:38.757381Z",
     "shell.execute_reply": "2025-09-07T05:38:38.756806Z",
     "shell.execute_reply.started": "2025-09-07T05:38:38.726641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382092</th>\n",
       "      <td>Third in command: Abu Zubaydah was only behind...</td>\n",
       "      <td>Abu Zubaydah was captured in 2002 .\\nGuantanam...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324565</th>\n",
       "      <td>PUBLISHED: . 15:55 EST, 2 January 2014 . | . U...</td>\n",
       "      <td>Department for International Development is fu...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513742</th>\n",
       "      <td>He had already flown from Kansas to Colorado, ...</td>\n",
       "      <td>US anti-abortion campaigner Troy Newman has be...</td>\n",
       "      <td>XSum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779596</th>\n",
       "      <td>Washington (CNN)Former New York Gov. Mario Cuo...</td>\n",
       "      <td>Gov. Mario Cuomo's most lasting legacy remains...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631883</th>\n",
       "      <td>A tornado claimed the lives of four people in ...</td>\n",
       "      <td>A boy at River Valley Ranch Christian summer c...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157704</th>\n",
       "      <td>The blast happened in the Sorkhrot district of...</td>\n",
       "      <td>At least 12 people have been killed and dozens...</td>\n",
       "      <td>XSum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741690</th>\n",
       "      <td>By . Jennifer Newton . A polar bear who surviv...</td>\n",
       "      <td>The female bear has been pictured with her sec...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163889</th>\n",
       "      <td>By . Marco Pierre White . PUBLISHED: . 18:37 E...</td>\n",
       "      <td>Marco Pierre White celebrates the results of a...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757621</th>\n",
       "      <td>A convicted sex offender groped a nine-year-ol...</td>\n",
       "      <td>Court told Peter Grant groped nine-year-old in...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356655</th>\n",
       "      <td>Chelsea's highly rated midfielder Nathaniel Ch...</td>\n",
       "      <td>20-year-old Nathaniel Chalobah can play in mid...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content  \\\n",
       "382092  Third in command: Abu Zubaydah was only behind...   \n",
       "324565  PUBLISHED: . 15:55 EST, 2 January 2014 . | . U...   \n",
       "513742  He had already flown from Kansas to Colorado, ...   \n",
       "779596  Washington (CNN)Former New York Gov. Mario Cuo...   \n",
       "631883  A tornado claimed the lives of four people in ...   \n",
       "157704  The blast happened in the Sorkhrot district of...   \n",
       "741690  By . Jennifer Newton . A polar bear who surviv...   \n",
       "163889  By . Marco Pierre White . PUBLISHED: . 18:37 E...   \n",
       "757621  A convicted sex offender groped a nine-year-ol...   \n",
       "356655  Chelsea's highly rated midfielder Nathaniel Ch...   \n",
       "\n",
       "                                                  Summary         Dataset  \n",
       "382092  Abu Zubaydah was captured in 2002 .\\nGuantanam...  CNN/Daily Mail  \n",
       "324565  Department for International Development is fu...  CNN/Daily Mail  \n",
       "513742  US anti-abortion campaigner Troy Newman has be...            XSum  \n",
       "779596  Gov. Mario Cuomo's most lasting legacy remains...  CNN/Daily Mail  \n",
       "631883  A boy at River Valley Ranch Christian summer c...  CNN/Daily Mail  \n",
       "157704  At least 12 people have been killed and dozens...            XSum  \n",
       "741690  The female bear has been pictured with her sec...  CNN/Daily Mail  \n",
       "163889  Marco Pierre White celebrates the results of a...  CNN/Daily Mail  \n",
       "757621  Court told Peter Grant groped nine-year-old in...  CNN/Daily Mail  \n",
       "356655  20-year-old Nathaniel Chalobah can play in mid...  CNN/Daily Mail  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:29:21.241564Z",
     "iopub.status.busy": "2025-09-09T05:29:21.241216Z",
     "iopub.status.idle": "2025-09-09T05:29:21.546057Z",
     "shell.execute_reply": "2025-09-09T05:29:21.545157Z",
     "shell.execute_reply.started": "2025-09-09T05:29:21.241543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cnn=df[df['Dataset']==\"CNN/Daily Mail\"]\n",
    "df_xsum=df[df['Dataset']==\"XSum\"]\n",
    "df_other=df[df['Dataset']==\"Multi-News\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:38:39.020956Z",
     "iopub.status.busy": "2025-09-07T05:38:39.020668Z",
     "iopub.status.idle": "2025-09-07T05:38:39.027104Z",
     "shell.execute_reply": "2025-09-07T05:38:39.026262Z",
     "shell.execute_reply.started": "2025-09-07T05:38:39.020930Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content  \\\n",
      "0  New York police are concerned drones could bec...   \n",
      "1  By . Ryan Lipman . Perhaps Australian porn sta...   \n",
      "2  This was, Sergio Garcia conceded, much like be...   \n",
      "3  An Ebola outbreak that began in Guinea four mo...   \n",
      "4  By . Associated Press and Daily Mail Reporter ...   \n",
      "\n",
      "                                             Summary         Dataset  \n",
      "0  Police have investigated criminals who have ri...  CNN/Daily Mail  \n",
      "1  Porn star Angela White secretly filmed sex act...  CNN/Daily Mail  \n",
      "2  American draws inspiration from fellow country...  CNN/Daily Mail  \n",
      "3  World Health Organisation: 635 infections and ...  CNN/Daily Mail  \n",
      "4  A sinkhole opened up at 5:15am this morning in...  CNN/Daily Mail  \n",
      "(587594, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_cnn.head())\n",
    "print(df_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:38:39.028066Z",
     "iopub.status.busy": "2025-09-07T05:38:39.027814Z",
     "iopub.status.idle": "2025-09-07T05:38:39.044929Z",
     "shell.execute_reply": "2025-09-07T05:38:39.044155Z",
     "shell.execute_reply.started": "2025-09-07T05:38:39.028046Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Content  \\\n",
      "23  They were taken on as volunteers and the servi...   \n",
      "24  7 June 2016 Last updated at 20:23 BST\\nTown be...   \n",
      "30  Storms Desmond, Eva, Frank and Gertrude all ca...   \n",
      "33  Russia's economic development ministry estimat...   \n",
      "38  Some 80 locals, described by police as far-rig...   \n",
      "\n",
      "                                              Summary Dataset  \n",
      "23  An extra 60 counsellors were drafted in by the...    XSum  \n",
      "24  Terry Butcher has been recalling Alan Brazil's...    XSum  \n",
      "30  Borders councillors have been told the financi...    XSum  \n",
      "33  The Russian government has warned the economy ...    XSum  \n",
      "38  Residents have clashed with asylum seekers in ...    XSum  \n",
      "(226711, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_xsum.head())\n",
    "print(df_xsum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:38:39.048081Z",
     "iopub.status.busy": "2025-09-07T05:38:39.047895Z",
     "iopub.status.idle": "2025-09-07T05:38:39.063582Z",
     "shell.execute_reply": "2025-09-07T05:38:39.062928Z",
     "shell.execute_reply.started": "2025-09-07T05:38:39.048067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Content  \\\n",
      "20  She did it – and this time, that’s a good thin...   \n",
      "25  Once the negotiator arrives at the meeting poi...   \n",
      "37  A British woman who fell from a cruise ship sa...   \n",
      "41  Daiju Azuma. CC-BY-SA \\n  \\n Toxic chemicals a...   \n",
      "51  CANBERRA, Australia (AP) — A large shark was k...   \n",
      "\n",
      "                                              Summary     Dataset  \n",
      "20  – Tomorrow looks to be a milestone day for Lin...  Multi-News  \n",
      "25  – Brit Edwin Dyer was kidnapped in 2009 by al-...  Multi-News  \n",
      "37  – A woman on a Norwegian Cruise Line ship got ...  Multi-News  \n",
      "41  – Survival of the fittest in the depths of the...  Multi-News  \n",
      "51  – The first shark has been killed off Western ...  Multi-News  \n",
      "(56216, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_other.head())\n",
    "print(df_other.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:29:21.547311Z",
     "iopub.status.busy": "2025-09-09T05:29:21.547045Z",
     "iopub.status.idle": "2025-09-09T05:29:21.585680Z",
     "shell.execute_reply": "2025-09-09T05:29:21.584948Z",
     "shell.execute_reply.started": "2025-09-09T05:29:21.547284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_xsum=df_xsum.drop(columns=[\"Dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:38:39.105525Z",
     "iopub.status.busy": "2025-09-07T05:38:39.105351Z",
     "iopub.status.idle": "2025-09-07T05:38:39.110363Z",
     "shell.execute_reply": "2025-09-07T05:38:39.109695Z",
     "shell.execute_reply.started": "2025-09-07T05:38:39.105511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They were taken on as volunteers and the service has since decided to employ an extra four full-time counsellors.\n",
      "Documents seen by the BBC show its welfare and counselling team was almost halved between 2008 and June 2017.\n",
      "The London Fire Brigade said the mental health of staff was a \"main priority\".\n",
      "At least 80 people died in the fire in North Kensington on 14 June.\n",
      "More than 200 firefighters attended the tower block at the time, rescuing 65 people.\n",
      "The extra four full-time counsellors would effectively return staffing levels to those in 2008.\n",
      "The BBC understands there was the equivalent of 9.6 full-time counsellors working for the brigade in 2008. By the time of the fire, the number had been cut to 5.2.\n",
      "The London Fire Brigade is using its reserve budget to pay for the extra counsellors.\n",
      "But London Mayor Sadiq Khan has written to the government asking for it to provide extra funding for the fire service's staffing, as well as aerial appliances and improved breathing apparatus.\n",
      "The fire service did not confirm the extent of the support the 60 voluntary counsellors have given or if they are still being used.\n",
      "Siobhan McGee, a trauma specialist and former London Fire Brigade counsellor, said while firefighters were generally \"very resilient people\" it was normal for symptoms of traumatic stress to occur following a tragedy such as the Grenfell fire.\n",
      "\"They may be experiencing things like physically shaking in their body, elevated heart-rate,\" she told Victoria Derbyshire.\n",
      "\"They might have disturbed sleep, they might have nightmares, they might have induced images and flashbacks.\"\n",
      "She said over time, as trauma memory is processed by the brain, images and memories become less distressing.\n",
      "A spokesman for the London Fire Brigade said every firefighter who attended Grenfell was individually spoken to by a counsellor before they came off duty.\n",
      "\"When they returned to duty our staff also had access to a counsellor, and the brigade counselling team was reinforced by officer support from the NHS and other fire and rescue services,\" the spokesman said.\n",
      "\"Going forward, counsellors are visiting staff this week and carrying out a psychological health check of each individual and identifying further staff who might need support.\n",
      "\"We have an on-call counsellor available to all staff 24/7. The ongoing mental wellbeing of all of our staff continues to be a main priority.\"\n",
      "The Victoria Derbyshire programme is broadcast on weekdays between 09:00 and 11:00 on BBC Two and the BBC News channel.\n",
      "\n",
      "\n",
      "An extra 60 counsellors were drafted in by the London Fire Brigade to help firefighters traumatised by the Grenfell Tower fire, the Victoria Derbyshire programme has learned.\n"
     ]
    }
   ],
   "source": [
    "print(df_xsum.iloc[0,0])\n",
    "print(\"\\n\")\n",
    "print(df_xsum.iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:38:39.111880Z",
     "iopub.status.busy": "2025-09-07T05:38:39.111210Z",
     "iopub.status.idle": "2025-09-07T05:38:39.191173Z",
     "shell.execute_reply": "2025-09-07T05:38:39.190517Z",
     "shell.execute_reply.started": "2025-09-07T05:38:39.111859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 226711 entries, 23 to 870515\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Content  226677 non-null  object\n",
      " 1   Summary  226711 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_xsum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:29:21.587673Z",
     "iopub.status.busy": "2025-09-09T05:29:21.587404Z",
     "iopub.status.idle": "2025-09-09T05:29:21.727635Z",
     "shell.execute_reply": "2025-09-09T05:29:21.726860Z",
     "shell.execute_reply.started": "2025-09-09T05:29:21.587650Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_xsum=df_xsum.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:29:21.728622Z",
     "iopub.status.busy": "2025-09-09T05:29:21.728354Z",
     "iopub.status.idle": "2025-09-09T05:29:21.732485Z",
     "shell.execute_reply": "2025-09-09T05:29:21.731865Z",
     "shell.execute_reply.started": "2025-09-09T05:29:21.728581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_xsum.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T05:06:07.526770Z",
     "iopub.status.busy": "2025-09-08T05:06:07.526488Z",
     "iopub.status.idle": "2025-09-08T05:06:07.595384Z",
     "shell.execute_reply": "2025-09-08T05:06:07.594703Z",
     "shell.execute_reply.started": "2025-09-08T05:06:07.526731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 226677 entries, 0 to 226676\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Content  226677 non-null  object\n",
      " 1   Summary  226677 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_xsum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:29:21.733724Z",
     "iopub.status.busy": "2025-09-09T05:29:21.733329Z",
     "iopub.status.idle": "2025-09-09T05:29:21.747454Z",
     "shell.execute_reply": "2025-09-09T05:29:21.746762Z",
     "shell.execute_reply.started": "2025-09-09T05:29:21.733701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import html\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text,str):\n",
    "        text=str(text)\n",
    "    text=\" \".join(text.split())\n",
    "    text=html.unescape(text)\n",
    "    text=re.sub(r'[\\x00-\\x1F\\x7F]','',text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:29:21.748583Z",
     "iopub.status.busy": "2025-09-09T05:29:21.748330Z",
     "iopub.status.idle": "2025-09-09T05:29:33.455627Z",
     "shell.execute_reply": "2025-09-09T05:29:33.454812Z",
     "shell.execute_reply.started": "2025-09-09T05:29:21.748562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_xsum[\"Content\"]=df_xsum[\"Content\"].apply(preprocess_text)\n",
    "df_xsum[\"Summary\"]=df_xsum[\"Summary\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:38:50.821183Z",
     "iopub.status.busy": "2025-09-07T05:38:50.821003Z",
     "iopub.status.idle": "2025-09-07T05:38:50.828802Z",
     "shell.execute_reply": "2025-09-07T05:38:50.828102Z",
     "shell.execute_reply.started": "2025-09-07T05:38:50.821169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They were taken on as volunteers and the servi...</td>\n",
       "      <td>An extra 60 counsellors were drafted in by the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 June 2016 Last updated at 20:23 BST Town bea...</td>\n",
       "      <td>Terry Butcher has been recalling Alan Brazil's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Storms Desmond, Eva, Frank and Gertrude all ca...</td>\n",
       "      <td>Borders councillors have been told the financi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russia's economic development ministry estimat...</td>\n",
       "      <td>The Russian government has warned the economy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some 80 locals, described by police as far-rig...</td>\n",
       "      <td>Residents have clashed with asylum seekers in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  They were taken on as volunteers and the servi...   \n",
       "1  7 June 2016 Last updated at 20:23 BST Town bea...   \n",
       "2  Storms Desmond, Eva, Frank and Gertrude all ca...   \n",
       "3  Russia's economic development ministry estimat...   \n",
       "4  Some 80 locals, described by police as far-rig...   \n",
       "\n",
       "                                             Summary  \n",
       "0  An extra 60 counsellors were drafted in by the...  \n",
       "1  Terry Butcher has been recalling Alan Brazil's...  \n",
       "2  Borders councillors have been told the financi...  \n",
       "3  The Russian government has warned the economy ...  \n",
       "4  Residents have clashed with asylum seekers in ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xsum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:29:33.456730Z",
     "iopub.status.busy": "2025-09-09T05:29:33.456448Z",
     "iopub.status.idle": "2025-09-09T05:29:34.148150Z",
     "shell.execute_reply": "2025-09-09T05:29:34.147339Z",
     "shell.execute_reply.started": "2025-09-09T05:29:33.456707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_temp,y_train,y_temp=train_test_split(df_xsum[\"Content\"],df_xsum[\"Summary\"],\n",
    "                                               test_size=0.2,\n",
    "                                              random_state=SEED)\n",
    "x_test,x_val,y_test,y_val=train_test_split(x_temp,y_temp,\n",
    "                                               test_size=0.5,\n",
    "                                              random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:34:39.751215Z",
     "iopub.status.busy": "2025-09-09T05:34:39.750913Z",
     "iopub.status.idle": "2025-09-09T05:34:44.288528Z",
     "shell.execute_reply": "2025-09-09T05:34:44.287728Z",
     "shell.execute_reply.started": "2025-09-09T05:34:39.751183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model_name='facebook/bart-base'\n",
    "tokenizer=BartTokenizer.from_pretrained(model_name)\n",
    "model=BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T14:40:38.031023Z",
     "iopub.status.busy": "2025-09-08T14:40:38.030285Z",
     "iopub.status.idle": "2025-09-08T14:40:38.035911Z",
     "shell.execute_reply": "2025-09-08T14:40:38.034923Z",
     "shell.execute_reply.started": "2025-09-08T14:40:38.030992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_len=[]\n",
    "\n",
    "def token_len(text):\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    tokenized_len.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:39:18.811149Z",
     "iopub.status.busy": "2025-09-07T05:39:18.810897Z",
     "iopub.status.idle": "2025-09-07T05:45:34.100398Z",
     "shell.execute_reply": "2025-09-07T05:45:34.099586Z",
     "shell.execute_reply.started": "2025-09-07T05:39:18.811127Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "226672    None\n",
       "226673    None\n",
       "226674    None\n",
       "226675    None\n",
       "226676    None\n",
       "Name: Content, Length: 226677, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xsum[\"Content\"].apply(token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:45:34.101794Z",
     "iopub.status.busy": "2025-09-07T05:45:34.101246Z",
     "iopub.status.idle": "2025-09-07T05:45:34.812412Z",
     "shell.execute_reply": "2025-09-07T05:45:34.811653Z",
     "shell.execute_reply.started": "2025-09-07T05:45:34.101747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(tokenized_len, bins=50)\n",
    "plt.xlabel(\"Token Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:45:34.813271Z",
     "iopub.status.busy": "2025-09-07T05:45:34.813097Z",
     "iopub.status.idle": "2025-09-07T05:45:34.833654Z",
     "shell.execute_reply": "2025-09-07T05:45:34.832919Z",
     "shell.execute_reply.started": "2025-09-07T05:45:34.813258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(tokenized_len,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:45:34.834739Z",
     "iopub.status.busy": "2025-09-07T05:45:34.834490Z",
     "iopub.status.idle": "2025-09-07T05:45:34.846954Z",
     "shell.execute_reply": "2025-09-07T05:45:34.846299Z",
     "shell.execute_reply.started": "2025-09-07T05:45:34.834716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_len_output=[]\n",
    "\n",
    "def token_len_out(text):\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    tokenized_len_output.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:45:34.847864Z",
     "iopub.status.busy": "2025-09-07T05:45:34.847631Z",
     "iopub.status.idle": "2025-09-07T05:45:58.669033Z",
     "shell.execute_reply": "2025-09-07T05:45:58.668185Z",
     "shell.execute_reply.started": "2025-09-07T05:45:34.847840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "226672    None\n",
       "226673    None\n",
       "226674    None\n",
       "226675    None\n",
       "226676    None\n",
       "Name: Summary, Length: 226677, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xsum[\"Summary\"].apply(token_len_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:45:58.672412Z",
     "iopub.status.busy": "2025-09-07T05:45:58.672199Z",
     "iopub.status.idle": "2025-09-07T05:45:59.294205Z",
     "shell.execute_reply": "2025-09-07T05:45:59.293512Z",
     "shell.execute_reply.started": "2025-09-07T05:45:58.672395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(tokenized_len_output,bins=50)\n",
    "plt.xlabel(\"Token Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T05:45:59.295162Z",
     "iopub.status.busy": "2025-09-07T05:45:59.294921Z",
     "iopub.status.idle": "2025-09-07T05:45:59.314580Z",
     "shell.execute_reply": "2025-09-07T05:45:59.314006Z",
     "shell.execute_reply.started": "2025-09-07T05:45:59.295138Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(tokenized_len_output,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:34:56.579960Z",
     "iopub.status.busy": "2025-09-09T05:34:56.579293Z",
     "iopub.status.idle": "2025-09-09T05:34:56.586328Z",
     "shell.execute_reply": "2025-09-09T05:34:56.585428Z",
     "shell.execute_reply.started": "2025-09-09T05:34:56.579929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_inp_len=768\n",
    "max_out_len=64\n",
    "\n",
    "def tokenize_fun(content , summary):\n",
    "    model_inputs=tokenizer(\n",
    "        content,\n",
    "        max_length=max_inp_len,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    labels=tokenizer(\n",
    "        summary,\n",
    "        max_length=max_out_len,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:34:58.729177Z",
     "iopub.status.busy": "2025-09-09T05:34:58.728570Z",
     "iopub.status.idle": "2025-09-09T05:47:37.999471Z",
     "shell.execute_reply": "2025-09-09T05:47:37.998802Z",
     "shell.execute_reply.started": "2025-09-09T05:34:58.729152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenize_fun(list(x_train), list(y_train))\n",
    "val_encodings   = tokenize_fun(list(x_val), list(y_val))\n",
    "test_encodings  = tokenize_fun(list(x_test), list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:47:38.000767Z",
     "iopub.status.busy": "2025-09-09T05:47:38.000536Z",
     "iopub.status.idle": "2025-09-09T05:48:54.427874Z",
     "shell.execute_reply": "2025-09-09T05:48:54.427063Z",
     "shell.execute_reply.started": "2025-09-09T05:47:38.000749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:48:54.429251Z",
     "iopub.status.busy": "2025-09-09T05:48:54.428966Z",
     "iopub.status.idle": "2025-09-09T05:48:54.435064Z",
     "shell.execute_reply": "2025-09-09T05:48:54.434265Z",
     "shell.execute_reply.started": "2025-09-09T05:48:54.429224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class XSumDataset(Dataset):\n",
    "    def __init__(self,encodings):\n",
    "        self.encodings=encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        item={}\n",
    "        for key,val in self.encodings.items():\n",
    "            item[key]=val[idx]\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:48:54.437191Z",
     "iopub.status.busy": "2025-09-09T05:48:54.436977Z",
     "iopub.status.idle": "2025-09-09T05:48:54.450262Z",
     "shell.execute_reply": "2025-09-09T05:48:54.449524Z",
     "shell.execute_reply.started": "2025-09-09T05:48:54.437163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset=XSumDataset(train_encodings)\n",
    "test_dataset=XSumDataset(test_encodings)\n",
    "val_dataset=XSumDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:48:54.451366Z",
     "iopub.status.busy": "2025-09-09T05:48:54.451106Z",
     "iopub.status.idle": "2025-09-09T05:48:54.524931Z",
     "shell.execute_reply": "2025-09-09T05:48:54.524361Z",
     "shell.execute_reply.started": "2025-09-09T05:48:54.451343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig,get_peft_model\n",
    "\n",
    "target_modules = [\"q_proj\", \"v_proj\"]\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                # rank of the low-rank matrices\n",
    "    lora_alpha=16,      # scaling factor\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",        # no bias updates\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "model= get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:48:54.525902Z",
     "iopub.status.busy": "2025-09-09T05:48:54.525694Z",
     "iopub.status.idle": "2025-09-09T05:48:57.515683Z",
     "shell.execute_reply": "2025-09-09T05:48:57.514868Z",
     "shell.execute_reply.started": "2025-09-09T05:48:54.525886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BartForConditionalGeneration(\n",
       "      (model): BartModel(\n",
       "        (shared): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "        (encoder): BartEncoder(\n",
       "          (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "          (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "          (layers): ModuleList(\n",
       "            (0-5): 6 x BartEncoderLayer(\n",
       "              (self_attn): BartSdpaAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): BartDecoder(\n",
       "          (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
       "          (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "          (layers): ModuleList(\n",
       "            (0-5): 6 x BartDecoderLayer(\n",
       "              (self_attn): BartSdpaAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): BartSdpaAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:58:47.655265Z",
     "iopub.status.busy": "2025-09-09T05:58:47.654964Z",
     "iopub.status.idle": "2025-09-09T05:58:47.701654Z",
     "shell.execute_reply": "2025-09-09T05:58:47.700988Z",
     "shell.execute_reply.started": "2025-09-09T05:58:47.655242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=3e-5,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=[],\n",
    "    log_level=\"info\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T05:58:51.982682Z",
     "iopub.status.busy": "2025-09-09T05:58:51.982074Z",
     "iopub.status.idle": "2025-09-09T08:39:08.435567Z",
     "shell.execute_reply": "2025-09-09T08:39:08.434930Z",
     "shell.execute_reply.started": "2025-09-09T05:58:51.982657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 181,341\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 11,334\n",
      "  Number of trainable parameters = 442,368\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11334' max='11334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11334/11334 2:32:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.955800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.657800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.547900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.552800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.528300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.504800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.480600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.519400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.500700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.427900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.425500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>2.413600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.418300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>2.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.418200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>2.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>2.394800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>2.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.403700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>2.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>2.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>2.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>2.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>2.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>2.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>2.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>2.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>2.413600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>2.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>2.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>2.426800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>2.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>2.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>2.397300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>2.452300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.413400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>2.389200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>2.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>2.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>2.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>2.411400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>2.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>2.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>2.414900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>2.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>2.373600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>2.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>2.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.374900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>2.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>2.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>2.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>2.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>2.424600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>2.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>2.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>2.389100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>2.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>2.426300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>2.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>2.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.434500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>2.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>2.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>2.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>2.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.367000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>2.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>2.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>2.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>2.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.405600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>2.372800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>2.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>2.424200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-10500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-11000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-11334\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-11334/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-11334/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-10500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22668\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5667' max='5667' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5667/5667 07:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.046839475631714,\n",
       " 'eval_runtime': 453.9902,\n",
       " 'eval_samples_per_second': 49.931,\n",
       " 'eval_steps_per_second': 12.483,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T09:12:00.921271Z",
     "iopub.status.busy": "2025-09-09T09:12:00.920949Z",
     "iopub.status.idle": "2025-09-09T11:51:32.932477Z",
     "shell.execute_reply": "2025-09-09T11:51:32.931838Z",
     "shell.execute_reply.started": "2025-09-09T09:12:00.921251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 181,341\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 11,334\n",
      "  Number of trainable parameters = 442,368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11334' max='11334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11334/11334 2:31:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.383100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.404900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.368600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.378100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.390100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.371200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.373600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.412400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.378300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.378500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.362400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.364600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.360100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>2.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>2.410100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.374600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.369200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.360600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>2.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>2.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>2.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.363400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>2.384800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>2.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>2.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>2.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.379800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>2.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>2.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>2.383500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>2.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.366100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>2.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>2.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>2.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>2.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.357600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>2.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>2.369500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>2.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>2.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>2.354300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>2.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>2.403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>2.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>2.376900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>2.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>2.373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>2.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>2.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>2.366900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>2.370600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.335200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>2.379400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>2.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>2.371300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>2.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>2.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>2.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>2.378400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>2.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>2.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>2.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>2.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>2.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.389400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>2.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>2.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>2.359600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>2.374300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.342100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>2.367200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>2.337200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>2.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>2.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>2.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>2.349200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>2.391600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-10500\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-11000\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/checkpoint-11334\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/checkpoint-11334/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-11334/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-10500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22668\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.027106523513794,\n",
       " 'eval_runtime': 452.1814,\n",
       " 'eval_samples_per_second': 50.13,\n",
       " 'eval_steps_per_second': 12.533,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.args.num_train_epochs = 1\n",
    "\n",
    "# Continue training\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T12:04:29.555726Z",
     "iopub.status.busy": "2025-09-09T12:04:29.555408Z",
     "iopub.status.idle": "2025-09-09T12:04:29.938099Z",
     "shell.execute_reply": "2025-09-09T12:04:29.937448Z",
     "shell.execute_reply.started": "2025-09-09T12:04:29.555702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./epoch2/final1_model\")\n",
    "tokenizer.save_pretrained(\"./epoch2/final1_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T12:05:01.376586Z",
     "iopub.status.busy": "2025-09-09T12:05:01.376316Z",
     "iopub.status.idle": "2025-09-09T12:05:02.372702Z",
     "shell.execute_reply": "2025-09-09T12:05:02.371754Z",
     "shell.execute_reply.started": "2025-09-09T12:05:01.376565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Zip the saved model folder\n",
    "!zip -r final1_model.zip ./epoch2/final1_model\n",
    "\n",
    "# Zip the saved tokenizer folder (if you saved it somewhere else)\n",
    "!zip -r final1_tokenizer.zip ./epoch2/final1_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T12:19:58.367165Z",
     "iopub.status.busy": "2025-09-09T12:19:58.366620Z",
     "iopub.status.idle": "2025-09-09T12:19:58.373747Z",
     "shell.execute_reply": "2025-09-09T12:19:58.373014Z",
     "shell.execute_reply.started": "2025-09-09T12:19:58.367138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model.eval()\n",
    "test_loader=DataLoader(test_dataset,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T12:32:42.849691Z",
     "iopub.status.busy": "2025-09-09T12:32:42.848915Z",
     "iopub.status.idle": "2025-09-09T12:32:42.854760Z",
     "shell.execute_reply": "2025-09-09T12:32:42.853935Z",
     "shell.execute_reply.started": "2025-09-09T12:32:42.849642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Stops the GenerationConfig from being printed\n",
    "logging.getLogger(\"transformers.generation_utils\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T12:32:55.098101Z",
     "iopub.status.busy": "2025-09-09T12:32:55.097816Z",
     "iopub.status.idle": "2025-09-09T13:23:32.774902Z",
     "shell.execute_reply": "2025-09-09T13:23:32.774175Z",
     "shell.execute_reply.started": "2025-09-09T12:32:55.098080Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5667/5667 [50:37<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids=batch['input_ids'].to(device)\n",
    "    attention_mask=batch['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs=model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=60,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    decoded_summaries=tokenizer.batch_decode(outputs,skip_special_tokens=True)\n",
    "    predictions.extend(decoded_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:34:44.574307Z",
     "iopub.status.busy": "2025-09-09T13:34:44.574008Z",
     "iopub.status.idle": "2025-09-09T13:34:44.598754Z",
     "shell.execute_reply": "2025-09-09T13:34:44.598068Z",
     "shell.execute_reply.started": "2025-09-09T13:34:44.574285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "references=list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:37:20.600723Z",
     "iopub.status.busy": "2025-09-09T13:37:20.600214Z",
     "iopub.status.idle": "2025-09-09T13:37:20.605250Z",
     "shell.execute_reply": "2025-09-09T13:37:20.604648Z",
     "shell.execute_reply.started": "2025-09-09T13:37:20.600700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two people have been found dead after a fire at a farmhouse in Sheffield.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:37:23.563432Z",
     "iopub.status.busy": "2025-09-09T13:37:23.562909Z",
     "iopub.status.idle": "2025-09-09T13:37:23.568319Z",
     "shell.execute_reply": "2025-09-09T13:37:23.567631Z",
     "shell.execute_reply.started": "2025-09-09T13:37:23.563410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two people have been found dead after a fire in a building in Stannington.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:38:37.999807Z",
     "iopub.status.busy": "2025-09-09T13:38:37.999502Z",
     "iopub.status.idle": "2025-09-09T13:38:42.329901Z",
     "shell.execute_reply": "2025-09-09T13:38:42.328933Z",
     "shell.execute_reply.started": "2025-09-09T13:38:37.999784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:39:41.859771Z",
     "iopub.status.busy": "2025-09-09T13:39:41.859214Z",
     "iopub.status.idle": "2025-09-09T13:39:47.152972Z",
     "shell.execute_reply": "2025-09-09T13:39:47.151976Z",
     "shell.execute_reply.started": "2025-09-09T13:39:41.859748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:41:04.245338Z",
     "iopub.status.busy": "2025-09-09T13:41:04.245045Z",
     "iopub.status.idle": "2025-09-09T13:41:18.032083Z",
     "shell.execute_reply": "2025-09-09T13:41:18.031164Z",
     "shell.execute_reply.started": "2025-09-09T13:41:04.245317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 F1: 0.34386634374866587\n",
      "ROUGE-2 F1: 0.13019998883160344\n",
      "ROUGE-L F1: 0.2758558454426727\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"ROUGE-1 F1:\", results[\"rouge1\"])\n",
    "print(\"ROUGE-2 F1:\", results[\"rouge2\"])\n",
    "print(\"ROUGE-L F1:\", results[\"rougeL\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:45:24.045436Z",
     "iopub.status.busy": "2025-09-09T13:45:24.044878Z",
     "iopub.status.idle": "2025-09-09T13:45:27.880144Z",
     "shell.execute_reply": "2025-09-09T13:45:27.879170Z",
     "shell.execute_reply.started": "2025-09-09T13:45:24.045413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:45:43.791584Z",
     "iopub.status.busy": "2025-09-09T13:45:43.790849Z",
     "iopub.status.idle": "2025-09-09T13:48:18.181315Z",
     "shell.execute_reply": "2025-09-09T13:48:18.180371Z",
     "shell.execute_reply.started": "2025-09-09T13:45:43.791557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978238a1ad9b4a8797fd7bc20a23bef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1496db96d7744c280781c79fa2a8062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63267400c9d4fe8a0c4a7e9cfe83039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b131bb9e2dce44afa10ff7ea59687117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61afc9175204253ad0533263af7f9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae769c9ed67747d29e70c0fc0958aa75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertScore F1:  0.4049939215183258\n"
     ]
    }
   ],
   "source": [
    "import bert_score\n",
    "\n",
    "P,R,F1=bert_score.score(predictions,references,lang=\"en\",rescale_with_baseline=True)\n",
    "\n",
    "print(\"BertScore F1: \",F1.mean().item())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1912571,
     "sourceId": 3140615,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
